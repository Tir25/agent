# ğŸ›ï¸ The Sovereign Desktop

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Ollama](https://img.shields.io/badge/Ollama-Llama%203.2-green.svg)](https://ollama.ai/)

> **Your AI, Your Machine, Your Rules.**

A **local-first, offline-capable, multimodal Windows agent** that puts you in complete control. No cloud dependencies, no data leaving your machine, just pure AI-powered automation running entirely on your hardware.

---

## ğŸ¯ Philosophy

### Local-First
Every component of The Sovereign Desktop is designed to run locally. Your data never leaves your machine. Your commands are processed on your hardware. Your privacy is absolute.

### Offline-Capable
After the initial model download, The Sovereign Desktop operates completely offline. No internet connection required for:
- Voice command processing
- Screen understanding and OCR
- Task execution and automation
- Conversation memory and context

### Multimodal Intelligence
Powered by **Llama 3.2 Vision** via **Ollama**, The Sovereign Desktop can:
- **See** your screen and understand UI elements
- **Listen** to your voice commands
- **Speak** responses naturally
- **Act** on your behalf with precision

### Python-Based OS Control
Built with Python for maximum extensibility and transparency. Every action the agent takes is:
- Auditable (full action logging)
- Customizable (plug-in architecture)
- Reversible (undo support where possible)

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        VOICE LOOP                               â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚    â”‚   STT   â”‚â”€â”€â”€â–¶â”‚  SEMANTIC   â”‚â”€â”€â”€â–¶â”‚    TTS      â”‚           â”‚
â”‚    â”‚(Whisper)â”‚    â”‚   ROUTER    â”‚    â”‚  (Piper)    â”‚           â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CORE                                     â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚    â”‚   LLM ENGINE    â”‚    â”‚    CONTEXT MANAGER      â”‚           â”‚
â”‚    â”‚ (Ollama/Llama)  â”‚    â”‚  (Memory + State)       â”‚           â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PERCEPTION    â”‚ â”‚  ACTUATORS  â”‚ â”‚   INTERFACES    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Vision   â”‚  â”‚ â”‚ â”‚ Windows â”‚ â”‚ â”‚  â”‚  Voice    â”‚  â”‚
â”‚  â”‚ Processingâ”‚  â”‚ â”‚ â”‚ Control â”‚ â”‚ â”‚  â”‚   Loop    â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚ â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Listeners â”‚  â”‚ â”‚ â”‚  Audio  â”‚ â”‚ â”‚  â”‚   TTS     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚                 â”‚ â”‚ â”‚ Browser â”‚ â”‚ â”‚  â”‚   STT     â”‚  â”‚
â”‚                 â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
sovereign-desktop/
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ pyproject.toml           # Project dependencies (Poetry)
â”œâ”€â”€ requirements.txt         # Dependencies (pip)
â”œâ”€â”€ config.yaml              # Main configuration
â”œâ”€â”€ main.py                  # Entry point
â”‚
â”œâ”€â”€ core/                    # ğŸ§  Brain of the agent
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ llm_engine.py       # Ollama/Llama integration
â”‚   â”œâ”€â”€ semantic_router.py  # Intent classification & routing
â”‚   â””â”€â”€ context_manager.py  # Memory and state management
â”‚
â”œâ”€â”€ perception/              # ğŸ‘ï¸ Sensory input
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vision.py           # Screen capture & processing
â”‚   â”œâ”€â”€ ocr.py              # Text extraction from screen
â”‚   â””â”€â”€ listeners.py        # Event listeners (keyboard, mouse)
â”‚
â”œâ”€â”€ actuators/               # ğŸ¦¾ Action execution
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ windows_control.py  # OS-level automation
â”‚   â”œâ”€â”€ audio_control.py    # Audio/media management
â”‚   â””â”€â”€ browser_agent.py    # Web automation
â”‚
â”œâ”€â”€ interfaces/              # ğŸ™ï¸ Human interaction
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ tts.py              # Text-to-Speech
â”‚   â”œâ”€â”€ stt.py              # Speech-to-Text
â”‚   â””â”€â”€ voice_loop.py       # Continuous voice interaction
â”‚
â”œâ”€â”€ utils/                   # ğŸ”§ Utilities
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py           # Configuration management
â”‚   â””â”€â”€ logging.py          # Logging infrastructure
â”‚
â””â”€â”€ tests/                   # âœ… Test suite
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_core/
    â”œâ”€â”€ test_perception/
    â”œâ”€â”€ test_actuators/
    â””â”€â”€ test_interfaces/
```

---

## ğŸš€ Quick Start

### Prerequisites

1. **Python 3.11+**
   ```bash
   python --version  # Should be 3.11 or higher
   ```

2. **Ollama with Llama 3.2 Vision**
   ```bash
   # Install Ollama from https://ollama.ai
   ollama pull llama3.2-vision
   ```

3. **Windows 10/11** (primary target platform)

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/sovereign-desktop.git
cd sovereign-desktop

# Create virtual environment
python -m venv venv
venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Configure the agent
copy config.example.yaml config.yaml
# Edit config.yaml with your preferences
```

### Running

```bash
# Start the agent
python main.py

# Or with voice mode
python main.py --voice

# Or with debug logging
python main.py --debug
```

---

## âš™ï¸ Configuration

Edit `config.yaml` to customize:

```yaml
llm:
  model: "llama3.2-vision"
  host: "http://localhost:11434"
  temperature: 0.7
  context_length: 8192

voice:
  stt_model: "base"  # whisper model size
  tts_voice: "default"
  wake_word: null  # or "hey sovereign"
  push_to_talk_key: "ctrl+space"

vision:
  capture_interval: 1.0  # seconds
  ocr_enabled: true

logging:
  level: "INFO"
  file: "logs/sovereign.log"
  max_size_mb: 100
```

---

## ğŸ”Œ Extensibility

### Adding New Tools

1. Create a new module in the appropriate directory
2. Implement the standard tool interface
3. Register with the semantic router

```python
# actuators/my_custom_tool.py
from core.semantic_router import register_tool

@register_tool(
    name="my_tool",
    description="Does something useful",
    triggers=["do the thing", "make it happen"]
)
def my_custom_tool(params: dict) -> str:
    # Your implementation
    return "Done!"
```

---

## ğŸ”’ Privacy & Security

- **100% Local Processing**: All AI inference runs on your machine
- **No Telemetry**: Zero data collection or phone-home behavior
- **Audit Trail**: Complete logging of all agent actions
- **Sandboxed**: Optional restricted mode for sensitive operations

---

## ğŸ“‹ Roadmap

See [PROJECT_ROADMAP.md](PROJECT_ROADMAP.md) for the detailed development plan.

- [x] Phase 1: Environment Setup
- [ ] Phase 2: Tool Creation
- [ ] Phase 3: Router Implementation
- [ ] Phase 4: Voice Integration
- [ ] Phase 5: Polish & Release

---

## ğŸ¤ Contributing

Contributions are welcome! Please read our contributing guidelines before submitting PRs.

---

## ğŸ“œ License

MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- [Ollama](https://ollama.ai/) - Local LLM inference
- [Meta's Llama](https://llama.meta.com/) - The foundation model
- [OpenAI Whisper](https://github.com/openai/whisper) - Speech recognition
- [Piper TTS](https://github.com/rhasspy/piper) - Local text-to-speech

---

<p align="center">
  <strong>The Sovereign Desktop</strong><br>
  <em>Your AI, Your Machine, Your Rules.</em>
</p>
